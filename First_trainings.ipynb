{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63a4b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.datasets import cifar10, imdb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "def preprocess_cifar10():\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    # Wybierz klasy 3 i 5\n",
    "    mask_train = np.logical_or(y_train == 3, y_train == 5).ravel()\n",
    "    X_train = X_train[mask_train]\n",
    "    y_train = y_train[mask_train]\n",
    "\n",
    "    mask_test = np.logical_or(y_test == 3, y_test == 5).ravel()\n",
    "    X_test = X_test[mask_test]\n",
    "    y_test = y_test[mask_test]\n",
    "    # Zmiana etykiet na binarne\n",
    "    y_train = np.where(y_train == 3, 0, 1)\n",
    "    y_test = np.where(y_test == 3, 0, 1)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def preprocess_imdb():\n",
    "    (X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"imdb.npz\",num_words=None,skip_top=0, maxlen=None,seed=1,start_char=1,oov_char=2,index_from=3)\n",
    "    # Odwróć indeks słownika IMDB, aby uzyskać mapowanie z indeksu na słowo\n",
    "    word_index = imdb.get_word_index()\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "    # Dekoduj recenzje do tekstów\n",
    "    decoded_train = [\" \".join([reverse_word_index.get(i - 3, \"?\") for i in review]) for review in X_train] #Dlaczego i - 3? - trzy pierwsze indeksy są zarezerwowane dla wartości specjalnych: start sekwencji, nieznane słowo i koniec sekwencji, więc indeksy rzeczywistych słów w słowniku są przesunięte o 3.\n",
    "    decoded_test = [\" \".join([reverse_word_index.get(i - 3, \"?\") for i in review]) for review in X_test]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=2500)\n",
    "    X_train = vectorizer.fit_transform(decoded_train)\n",
    "    X_test = vectorizer.transform(decoded_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def preprocess_breast_cancer():\n",
    "    data = load_breast_cancer()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def split_labeled_unlabeled(X, y, labeled_size):\n",
    "    X_labeled, X_unlabeled, y_labeled, _ = train_test_split(X, y, test_size=1-labeled_size, random_state=42, stratify=y)\n",
    "    return X_labeled, y_labeled, X_unlabeled\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(y_pred)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1_score\": f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "def preprocess_data(dataset_name):\n",
    "    if dataset_name == 'cifar10':\n",
    "        return preprocess_cifar10()\n",
    "    elif dataset_name == 'imdb':\n",
    "        return preprocess_imdb()\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        return preprocess_breast_cancer()\n",
    "\n",
    "def train_and_evaluate(dataset_name, model, X_train, y_train, X_unlabeled, X_test, y_test):\n",
    "    print(f\"Training model on {dataset_name}\")\n",
    "          \n",
    "    if dataset_name == 'cifar10':\n",
    "        y_train = y_train.ravel()\n",
    "        y_test = y_test.ravel()\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "        X_unlabeled = X_unlabeled.reshape(X_unlabeled.shape[0], -1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "        # Konwersja rzadkich macierzy do gęstych tablic dla danych IMDB\n",
    "    elif dataset_name == 'imdb':\n",
    "        X_train = X_train.toarray() if scipy.sparse.issparse(X_train) else X_train\n",
    "        X_unlabeled = X_unlabeled.toarray() if scipy.sparse.issparse(X_unlabeled) else X_unlabeled\n",
    "        X_test = X_test.toarray() if scipy.sparse.issparse(X_test) else X_test\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}, X_unlabeled shape: {X_unlabeled.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X=X_train, y=y_train, unlabeled_X=X_unlabeled)\n",
    "    training_time = time.time() - start_time\n",
    "    results = evaluate_model(model, X_test, y_test)\n",
    "    return results, training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10aebb",
   "metadata": {},
   "source": [
    "# <font color='green'>Tri-training</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07f973",
   "metadata": {},
   "source": [
    "### Hiperparametry modelu Tri-Training\n",
    "\n",
    "1. **base_estimator**: Pierwszy podstawowy uczeń w TriTraining.\n",
    "   - Możliwe wartości: dowolny klasyfikator zgodny z API `scikit-learn`.\n",
    "   \n",
    "   \n",
    "2. **base_estimator_2**: Drugi podstawowy uczeń w TriTraining.\n",
    "   - Możliwe wartości: dowolny klasyfikator zgodny z API `scikit-learn`.\n",
    "\n",
    "\n",
    "3. **base_estimator_3**: Trzeci podstawowy uczeń w TriTraining.\n",
    "   - Możliwe wartości: dowolny klasyfikator zgodny z API `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e2f757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cifar10\n",
      "X_labeled shape: (3000, 32, 32, 3), X_unlabeled shape: (7000, 32, 32, 3)\n",
      "y_labeled shape: (3000, 1)\n",
      "Training model on cifar10\n",
      "X_train shape: (3000, 3072), X_unlabeled shape: (7000, 3072)\n",
      "y_train shape: (3000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kaami\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1201: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\users\\kaami\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1201: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\users\\kaami\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1201: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10 Results: {'accuracy': 0.6355, 'precision': 0.66073546856465, 'recall': 0.557, 'f1_score': 0.6044492674986436}\n",
      "Training Time cifar10: 970.4850695133209\n",
      "\n",
      "Processing imdb\n",
      "X_labeled shape: (7500, 2500), X_unlabeled shape: (17500, 2500)\n",
      "y_labeled shape: (7500,)\n",
      "Training model on imdb\n",
      "X_train shape: (7500, 2500), X_unlabeled shape: (17500, 2500)\n",
      "y_train shape: (7500,)\n",
      "imdb Results: {'accuracy': 0.8428, 'precision': 0.8402954256670903, 'recall': 0.84648, 'f1_score': 0.8433763749402199}\n",
      "Training Time imdb: 133.80731654167175\n",
      "\n",
      "Processing breast_cancer\n",
      "X_labeled shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_labeled shape: (136,)\n",
      "Training model on breast_cancer\n",
      "X_train shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_train shape: (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kaami\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1201: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\users\\kaami\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1201: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast_cancer Results: {'accuracy': 0.9385964912280702, 'precision': 0.9102564102564102, 'recall': 1.0, 'f1_score': 0.953020134228188}\n",
      "Training Time breast_cancer: 0.9029445648193359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kaami\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1201: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "from LAMDA_SSL.Algorithm.Classification.Tri_Training import Tri_Training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Inicjalizacja modeli i danych\n",
    "datasets = ['cifar10', 'imdb', 'breast_cancer']\n",
    "labeled_size = 0.3\n",
    "base_estimators = [KNeighborsClassifier(n_neighbors=7), RandomForestClassifier(), LinearSVC(max_iter=10**4)]\n",
    "models = {dataset: Tri_Training(base_estimator=base_estimators[0], base_estimator_2=base_estimators[1], base_estimator_3=base_estimators[2]) for dataset in datasets}\n",
    "results = {}\n",
    "\n",
    "# Przetwarzanie danych i trenowanie modeli\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset}\")\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(dataset)\n",
    "    X_labeled, y_labeled, X_unlabeled = split_labeled_unlabeled(X_train, y_train, labeled_size)\n",
    "    print(f\"X_labeled shape: {X_labeled.shape}, X_unlabeled shape: {X_unlabeled.shape}\")\n",
    "    print(f\"y_labeled shape: {y_labeled.shape}\")\n",
    "    results[dataset], training_time = train_and_evaluate(dataset, models[dataset], X_labeled, y_labeled, X_unlabeled, X_test, y_test)\n",
    "    print(f\"{dataset} Results:\", results[dataset])\n",
    "    print(f\"Training Time {dataset}:\", training_time)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb7e2c",
   "metadata": {},
   "source": [
    "#  <font color='green'>ASSEMBLE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad9202",
   "metadata": {},
   "source": [
    "### Hiperparametry\n",
    "\n",
    "1. **base_estimator** - Podstawowy klasyfikator używany w uczeniu zespołowym. Dowolny klasyfikator zgodny z interfejsem sklearn (np. DecisionTreeClassifier, KNeighborsClassifier).\n",
    "\n",
    "\n",
    "2. **T** - Liczba podstawowych klasyfikatorów, równocześnie jest to liczba iteracji.\n",
    "    Możliwe wartości: Liczby całkowite większe od 0.\n",
    "\n",
    "\n",
    "3. **alpha** - Waga każdej próbki przy aktualizacji rozkładu próbkowania.\n",
    "    Możliwe wartości: Liczby rzeczywiste większe od 0.\n",
    "\n",
    "\n",
    "4. **beta** - Używany do inicjalizacji rozkładu próbkowania danych oznaczonych i nieoznaczonych.\n",
    "    Możliwe wartości: Liczby rzeczywiste w przedziale [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5dd602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing imdb\n",
      "X_labeled shape: (7500, 2500), X_unlabeled shape: (17500, 2500)\n",
      "y_labeled shape: (7500,)\n",
      "Training model on imdb\n",
      "X_train shape: (7500, 2500), X_unlabeled shape: (17500, 2500)\n",
      "y_train shape: (7500,)\n",
      "imdb Results: {'accuracy': 0.8132, 'precision': 0.8071069971760276, 'recall': 0.82312, 'f1_score': 0.8150348542458808}\n",
      "Training Time imdb: 460.310693025589\n",
      "\n",
      "Processing breast_cancer\n",
      "X_labeled shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_labeled shape: (136,)\n",
      "Training model on breast_cancer\n",
      "X_train shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_train shape: (136,)\n",
      "breast_cancer Results: {'accuracy': 0.956140350877193, 'precision': 0.9342105263157895, 'recall': 1.0, 'f1_score': 0.9659863945578232}\n",
      "Training Time breast_cancer: 3.2257578372955322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from LAMDA_SSL.Algorithm.Classification.Assemble import Assemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Inicjalizacja modeli i danych\n",
    "#datasets = ['cifar10','imdb', 'breast_cancer']\n",
    "datasets = ['imdb', 'breast_cancer']\n",
    "labeled_size = 0.3\n",
    "base_estimators = [KNeighborsClassifier(n_neighbors=7), RandomForestClassifier(), LinearSVC(max_iter=10**4)]\n",
    "T=10\n",
    "models = {dataset: Assemble(T=T,base_estimator=base_estimators[1]) for dataset in datasets}\n",
    "results = {}\n",
    "\n",
    "# Przetwarzanie danych i trenowanie modeli\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset}\")\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(dataset)\n",
    "    X_labeled, y_labeled, X_unlabeled = split_labeled_unlabeled(X_train, y_train, labeled_size)\n",
    "    print(f\"X_labeled shape: {X_labeled.shape}, X_unlabeled shape: {X_unlabeled.shape}\")\n",
    "    print(f\"y_labeled shape: {y_labeled.shape}\")\n",
    "    results[dataset], training_time = train_and_evaluate(dataset, models[dataset], X_labeled, y_labeled, X_unlabeled, X_test, y_test)\n",
    "    print(f\"{dataset} Results:\", results[dataset])\n",
    "    print(f\"Training Time {dataset}:\", training_time)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada321f4",
   "metadata": {},
   "source": [
    "#  <font color='green'>Semiboost</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b9fb2",
   "metadata": {},
   "source": [
    "### Hiperparametry \n",
    "\n",
    "1. **base_estimator**\n",
    "   - Opis: Bazowy nadzorowany uczeń używany w algorytmie.\n",
    "   - Możliwe wartości: Dowolny klasyfikator zgodny z interfejsem scikit-learn.\n",
    "\n",
    "\n",
    "2. **n_neighbors**\n",
    "   - Opis: Liczba sąsiadów w funkcji kernela 'knn'.\n",
    "   - Możliwe wartości: Dowolna liczba całkowita większa od 0.\n",
    "\n",
    "\n",
    "3. **n_jobs**\n",
    "   - Opis: Liczba równoległych zadań w funkcji kernela 'knn'.\n",
    "   - Możliwe wartości: Dowolna liczba całkowita lub None.\n",
    "\n",
    "\n",
    "4. **T**\n",
    "   - Opis: Liczba bazowych uczących się, równa także liczbie iteracji.\n",
    "   - Możliwe wartości: Dowolna liczba całkowita większa od 0.\n",
    "\n",
    "\n",
    "5. **sample_percent**\n",
    "   - Opis: Procent próbek pobieranych w każdej iteracji jako proporcja pozostałych nieoznakowanych próbek.\n",
    "   - Możliwe wartości: Liczba zmiennoprzecinkowa od 0 do 1.\n",
    "\n",
    "\n",
    "6. **sigma_percentile**\n",
    "   - Opis: Parametr skali używany w kernelu 'rbf'.\n",
    "   - Możliwe wartości: Dowolna liczba zmiennoprzecinkowa większa od 0.\n",
    "\n",
    "\n",
    "7. **similarity_kernel**\n",
    "   - Opis: Typ kernela, 'rbf', 'knn' lub funkcja.\n",
    "   - Możliwe wartości: 'rbf', 'knn', 'linear' lub funkcja.\n",
    "\n",
    "\n",
    "8. **gamma**\n",
    "   - Opis: Wartość gamma dla kernela 'rbf'.\n",
    "   - Możliwe wartości: Dowolna liczba zmiennoprzecinkowa większa od 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b70190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing imdb\n",
      "X_labeled shape: (7500, 2500), X_unlabeled shape: (17500, 2500)\n",
      "y_labeled shape: (7500,)\n",
      "Training model on imdb\n",
      "X_train shape: (7500, 2500), X_unlabeled shape: (17500, 2500)\n",
      "y_train shape: (7500,)\n",
      "imdb Results: {'accuracy': 0.744, 'precision': 0.9117170626349892, 'recall': 0.54032, 'f1_score': 0.6785211975085392}\n",
      "Training Time imdb: 4773.320457458496\n",
      "\n",
      "Processing breast_cancer\n",
      "X_labeled shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_labeled shape: (136,)\n",
      "Training model on breast_cancer\n",
      "X_train shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_train shape: (136,)\n",
      "breast_cancer Results: {'accuracy': 0.9649122807017544, 'precision': 0.958904109589041, 'recall': 0.9859154929577465, 'f1_score': 0.9722222222222222}\n",
      "Training Time breast_cancer: 2.3200249671936035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from LAMDA_SSL.Algorithm.Classification.SemiBoost import SemiBoost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Inicjalizacja modeli i danych\n",
    "#datasets = ['cifar10','imdb', 'breast_cancer']\n",
    "datasets = ['imdb', 'breast_cancer']\n",
    "labeled_size = 0.3\n",
    "T=10\n",
    "base_estimators = [KNeighborsClassifier(n_neighbors=7), RandomForestClassifier(), LinearSVC(max_iter=10**4)]\n",
    "models = {dataset: SemiBoost(T=T,base_estimator=base_estimators[1]) for dataset in datasets}\n",
    "results = {}\n",
    "\n",
    "# Przetwarzanie danych i trenowanie modeli\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset}\")\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(dataset)\n",
    "    X_labeled, y_labeled, X_unlabeled = split_labeled_unlabeled(X_train, y_train, labeled_size)\n",
    "    print(f\"X_labeled shape: {X_labeled.shape}, X_unlabeled shape: {X_unlabeled.shape}\")\n",
    "    print(f\"y_labeled shape: {y_labeled.shape}\")\n",
    "    results[dataset], training_time = train_and_evaluate(dataset, models[dataset], X_labeled, y_labeled, X_unlabeled, X_test, y_test)\n",
    "    print(f\"{dataset} Results:\", results[dataset])\n",
    "    print(f\"Training Time {dataset}:\", training_time)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ef759",
   "metadata": {},
   "source": [
    "# <font color='green'>LapSVM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157568ba",
   "metadata": {},
   "source": [
    "### Hiperparametry\n",
    "\n",
    "1. **distance_function**\n",
    "    - Funkcja odległości używana do budowy grafu. Ten parametr jest ważny, gdy neighbor_mode jest None.\n",
    "    - Możliwe wartości: Zależne od implementacji, ale często obejmują funkcje takie jak 'knn', 'linear', 'rbf' oraz dowolne funkcje zdefiniowane przez użytkownika.\n",
    "\n",
    "\n",
    "2. **gamma_d**\n",
    "    - Opis: Parametr kernela związany z distance_function.\n",
    "    - Możliwe wartości: Dowolna liczba rzeczywista, zależna od specyficznej funkcji odległości.\n",
    "\n",
    "\n",
    "3. **neighbor_mode**\n",
    "    - Opis: Tryb krawędzi po zbudowaniu modelu grafu przez k-najbliższych sąsiadów. Opcje to 'connectivity' (zwraca macierz 0-1) i 'distance' (zwraca macierz odległości).\n",
    "    - Możliwe wartości: 'connectivity', 'distance'.\n",
    "\n",
    "\n",
    "4. **t**\n",
    "    - Opis: Parametr używany w obliczeniach, szczególnie gdy distance_function jest 'knn'.\n",
    "    - Możliwe wartości: Dowolna liczba rzeczywista.\n",
    "\n",
    "\n",
    "5. **n_neighbor**\n",
    "    - Opis: Wartość k w k-najbliższych sąsiadów.\n",
    "    - Możliwe wartości: Dowolna liczba całkowita.\n",
    "\n",
    "\n",
    "6. **kernel_function**\n",
    "    - Opis: Funkcja kernela odpowiadająca SVM.\n",
    "    - Możliwe wartości: Zazwyczaj 'rbf', 'linear' lub dowolna funkcja zdefiniowana przez użytkownika.\n",
    "\n",
    "\n",
    "7. **gamma_k**\n",
    "    - Opis: Parametr gamma odpowiadający kernel_function.\n",
    "    - Możliwe wartości: Dowolna liczba rzeczywista.\n",
    "\n",
    "\n",
    "8. **gamma_A**\n",
    "    - Opis: Waga kary za złożoność funkcji.\n",
    "    - Możliwe wartości: Dowolna liczba rzeczywista.\n",
    "\n",
    "\n",
    "9. **gamma_I**\n",
    "    - Opis: Waga kary za gładkość rozkładu danych.\n",
    "    - Możliwe wartości: Dowolna liczba rzeczywista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "603670ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing breast_cancer\n",
      "X_labeled shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_labeled shape: (136,)\n",
      "Training model on breast_cancer\n",
      "X_train shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_train shape: (136,)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "breast_cancer Results: {'accuracy': 0.6228070175438597, 'precision': 0.6228070175438597, 'recall': 1.0, 'f1_score': 0.7675675675675676}\n",
      "Training Time breast_cancer: 0.09562420845031738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from LAMDA_SSL.Algorithm.Classification.LapSVM import LapSVM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Inicjalizacja modeli i danych\n",
    "#datasets = ['cifar10','imdb', 'breast_cancer']\n",
    "#datasets = ['imdb', 'breast_cancer']\n",
    "datasets = ['breast_cancer']\n",
    "labeled_size = 0.3\n",
    "models = {dataset: LapSVM() for dataset in datasets}\n",
    "results = {}\n",
    "\n",
    "# Przetwarzanie danych i trenowanie modeli\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset}\")\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(dataset)\n",
    "    X_labeled, y_labeled, X_unlabeled = split_labeled_unlabeled(X_train, y_train, labeled_size)\n",
    "    print(f\"X_labeled shape: {X_labeled.shape}, X_unlabeled shape: {X_unlabeled.shape}\")\n",
    "    print(f\"y_labeled shape: {y_labeled.shape}\")\n",
    "    results[dataset], training_time = train_and_evaluate(dataset, models[dataset], X_labeled, y_labeled, X_unlabeled, X_test, y_test)\n",
    "    print(f\"{dataset} Results:\", results[dataset])\n",
    "    print(f\"Training Time {dataset}:\", training_time)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b20e5",
   "metadata": {},
   "source": [
    "# <font color='green'>Ladder networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc5876",
   "metadata": {},
   "source": [
    "# <font color='green'>$\\Pi$-model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb4bb8",
   "metadata": {},
   "source": [
    "# <font color='green'>Temporal ensembling</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7869702b",
   "metadata": {},
   "source": [
    "### Hiperparametry TemporalEnsembling\n",
    "\n",
    "- `lambda_u` (waga straty nienadzorowanej): \n",
    "  - Możliwe wartości: dowolna liczba zmiennoprzecinkowa.\n",
    "\n",
    "- `ema_weight` (waga aktualizacji dla eksponencjalnie ważonej średniej ruchomej pseudoetykiet):\n",
    "  - Możliwe wartości: dowolna liczba zmiennoprzecinkowa między 0 a 1.\n",
    "\n",
    "- `warmup` (koniec okresu rozgrzewki):\n",
    "  - Możliwe wartości: procent całkowitej liczby iteracji, np. 0.4 oznacza 40% całkowitej liczby iteracji.\n",
    "\n",
    "- `num_classes` (liczba klas):\n",
    "  - Możliwe wartości: dowolna liczba całkowita.\n",
    "\n",
    "- `num_samples` (liczba próbek):\n",
    "  - Możliwe wartości: dowolna liczba całkowita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7426b0fb",
   "metadata": {},
   "source": [
    "# <font color='green'>Mean teacher</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f4ef9",
   "metadata": {},
   "source": [
    "### Hiperparametry\n",
    "\n",
    "- **lambda_u**\n",
    "    - Waga straty nienadzorowanej. Możliwe wartości zależą od specyfiki zadania, ale często wybiera się wartości z zakresu 0.1 do 1.\n",
    "\n",
    "- **warmup**\n",
    "    - Końcowy punkt okresu rozgrzewki. Jeśli num_it_total wynosi 100, a warmup jest ustawione na 0.4, to rozgrzewka odbywa się w pierwszych 40 iteracjach. Możliwe wartości to liczby z zakresu od 0 do 1.\n",
    "\n",
    "- **ema_decay**\n",
    "    - Współczynnik zaniku dla eksponencjalnego średniego ruchomego. Typowe wartości to liczby z zakresu od 0.9 do 0.999.\n",
    "\n",
    "- **weight_decay**\n",
    "    - Współczynnik regularyzacji, który pomaga zapobiegać przeuczeniu. Zwykle wybiera się wartości od 0.0001 do 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26dab36",
   "metadata": {},
   "source": [
    "# <font color='green'>VAT Virtual Adversarial Training</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a3d3b",
   "metadata": {},
   "source": [
    "### Hiperparametry\n",
    "\n",
    "- **lambda_u** (waga straty nienadzorowanej):\n",
    "    - Możliwe wartości: liczby zmiennoprzecinkowe, zazwyczaj w zakresie od 0 do 1.\n",
    "\n",
    "\n",
    "- **eps** (poziom szumu):\n",
    "    - Możliwe wartości: małe liczby zmiennoprzecinkowe, zazwyczaj poniżej 1.\n",
    "\n",
    "\n",
    "- **warmup** (koniec okresu rozgrzewki):\n",
    "    - Możliwe wartości: liczby zmiennoprzecinkowe z zakresu od 0 do 1, wskazujące na proporcję liczby iteracji, w których odbywa się rozgrzewka.\n",
    "\n",
    "\n",
    "- **xi** (parametr skali dla zakłóceń):\n",
    "    - Możliwe wartości: małe liczby zmiennoprzecinkowe, często bliskie 0.\n",
    "\n",
    "\n",
    "- **lambda_entmin** (waga straty z minimalizacji entropii):\n",
    "    - Możliwe wartości: liczby zmiennoprzecinkowe, zwykle w zakresie od 0 do 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e642bc8",
   "metadata": {},
   "source": [
    "# Transductive\n",
    "## <font color='green'>TSVM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c9c67",
   "metadata": {},
   "source": [
    "### Hiperparametry\n",
    "\n",
    "- `Cl` (Waga próbek oznaczonych)\n",
    "    - Dowolna wartość liczby rzeczywistej.\n",
    "\n",
    "\n",
    "- `Cu` (Waga próbek nieoznaczonych)\n",
    "    - Dowolna wartość liczby rzeczywistej.\n",
    "\n",
    "\n",
    "- `kernel` (Typ jądra)\n",
    "    - Możliwe wartości to 'rbf', 'knn' lub funkcja wywoływalna.\n",
    "\n",
    "\n",
    "- `degree` (Stopień wielomianu)\n",
    "    - Dotyczy jądra 'poly', wartości całkowite.\n",
    "\n",
    "\n",
    "- `gamma` (Parametr gamma)\n",
    "    - Dotyczy jąder 'rbf', 'poly', 'sigmoid', dowolna wartość liczby rzeczywistej.\n",
    "\n",
    "\n",
    "- `coef0` (Stała składowa funkcji jądra)\n",
    "    - Dotyczy jąder 'poly' i 'sigmoid', dowolna wartość liczby rzeczywistej.\n",
    "\n",
    "\n",
    "- `shrinking` (Użycie heurystyki skurczania)\n",
    "    - Wartości `True` lub `False`.\n",
    "\n",
    "\n",
    "- `probability` (Wagi dla klasyfikacji kąta obrotu)\n",
    "    - Dowolna wartość liczby rzeczywistej.\n",
    "\n",
    "\n",
    "- `tol` (Tolerancja na zatrzymanie treningu)\n",
    "    - Dowolna wartość liczby rzeczywistej, domyślnie 1e-3.\n",
    "\n",
    "\n",
    "- `cache_size` (Rozmiar pamięci podręcznej funkcji jądra)\n",
    "    - Dowolna wartość liczby rzeczywistej.\n",
    "\n",
    "\n",
    "- `class_weight` (Wagi różnych klas)\n",
    "    - Słownik lub 'balanced'.\n",
    "\n",
    "\n",
    "- `max_iter` (Maksymalna liczba iteracji)\n",
    "    - Wartość całkowita, `-1` dla nieograniczonej liczby.\n",
    "\n",
    "\n",
    "- `decision_function_shape` (Kształt funkcji decyzyjnej)\n",
    "    - 'ovo' lub 'ovr', domyślnie 'ovr'.\n",
    "\n",
    "\n",
    "- `break_ties` (Decyzja w przypadku remisu)\n",
    "    - Wartości `True` lub `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2bf328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing breast_cancer\n",
      "X_labeled shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_labeled shape: (136,)\n",
      "Training model on breast_cancer\n",
      "X_train shape: (136, 30), X_unlabeled shape: (319, 30)\n",
      "y_train shape: (136,)\n",
      "[1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1\n",
      " 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1\n",
      " 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0\n",
      " 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0\n",
      " 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [114, 319]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-765b67658c54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"X_labeled shape: {X_labeled.shape}, X_unlabeled shape: {X_unlabeled.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"y_labeled shape: {y_labeled.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_labeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_labeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_unlabeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{dataset} Results:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Training Time {dataset}:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-3860a16ba173>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(dataset_name, model, X_train, y_train, X_unlabeled, X_test, y_test)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlabeled_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_unlabeled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-3860a16ba173>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model, X_test, y_test)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     return {\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;34m\"precision\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;34m\"recall\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kaami\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kaami\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kaami\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    331\u001b[0m         raise ValueError(\n\u001b[0;32m    332\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [114, 319]"
     ]
    }
   ],
   "source": [
    "from LAMDA_SSL.Algorithm.Classification.TSVM import TSVM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Inicjalizacja modeli i danych\n",
    "#datasets = ['cifar10','imdb', 'breast_cancer']\n",
    "#datasets = ['imdb', 'breast_cancer']\n",
    "datasets = ['breast_cancer']\n",
    "labeled_size = 0.3\n",
    "models = {dataset: TSVM() for dataset in datasets}\n",
    "results = {}\n",
    "\n",
    "# Przetwarzanie danych i trenowanie modeli\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset}\")\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(dataset)\n",
    "    X_labeled, y_labeled, X_unlabeled = split_labeled_unlabeled(X_train, y_train, labeled_size)\n",
    "    print(f\"X_labeled shape: {X_labeled.shape}, X_unlabeled shape: {X_unlabeled.shape}\")\n",
    "    print(f\"y_labeled shape: {y_labeled.shape}\")\n",
    "    results[dataset], training_time = train_and_evaluate(dataset, models[dataset], X_labeled, y_labeled, X_unlabeled, X_test, y_test)\n",
    "    print(f\"{dataset} Results:\", results[dataset])\n",
    "    print(f\"Training Time {dataset}:\", training_time)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb542ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54be78e4",
   "metadata": {},
   "source": [
    "# <font color='green'>Label propagation algorithm for inference on graphs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c03fe",
   "metadata": {},
   "source": [
    "### Hiperparametry\n",
    "\n",
    "- **kernel**\n",
    "    - Opis: Funkcja jądra, która może być podana jako ciąg znaków 'rbf' lub 'knn', lub jako funkcja.\n",
    "    - Możliwe wartości: 'rbf', 'knn', funkcja.\n",
    "\n",
    "\n",
    "- **gamma**\n",
    "    - Opis: Wartość gamma, gdy funkcja jądra to jądro RBF.\n",
    "    - Możliwe wartości: Liczba zmiennoprzecinkowa (float).\n",
    "\n",
    "\n",
    "- **n_neighbors**\n",
    "    - Opis: Liczba sąsiadów, gdy funkcja jądra to jądro 'n_neighbors'.\n",
    "    - Możliwe wartości: Liczba całkowita (int).\n",
    "\n",
    "\n",
    "- **max_iter**\n",
    "    - Opis: Maksymalna liczba iteracji.\n",
    "    - Możliwe wartości: Liczba całkowita (int).\n",
    "\n",
    "\n",
    "- **tol**\n",
    "    - Opis: Tolerancja zbieżności.\n",
    "    - Możliwe wartości: Liczba zmiennoprzecinkowa (float).\n",
    "\n",
    "\n",
    "- **n_jobs**\n",
    "    - Opis: Liczba równoległych zadań.\n",
    "    - Możliwe wartości: Liczba całkowita (int) lub None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a8a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BSc_venv",
   "language": "python",
   "name": "bsc_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
